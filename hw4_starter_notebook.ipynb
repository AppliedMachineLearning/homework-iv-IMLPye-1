{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Modeling Text Data\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI:  yo2258\n",
    "* Name: Ye Ouyang\n",
    "\n",
    "### Team Member 2 [optional]:\n",
    "* UNI:  \n",
    "* Name:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data here: https://data.boston.gov/dataset/vision-zero-entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1 - Data Cleaning  [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, visualize the class distribution. Clean up the target labels. Some categories have been arbitrarily split and need to be consolidated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your code for task 1 here. You may use multiple cells. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "#%% 1) Data Cleaning  \n",
    "\n",
    "# Load data and Visualize the class distribution\n",
    "reviews_train_raw = pd.read_csv (\"Vision_Zero_Entry.csv\")\n",
    "\n",
    "# Clean up the target labels\n",
    "reviews_train_raw = reviews_train_raw.drop('GLOBALID',axis=1)\n",
    "reviews_train=reviews_train_raw.dropna()\n",
    "\n",
    "# Class visulazation\n",
    "fig, ax = plt.subplots()\n",
    "reviews_train.REQUESTTYPE.value_counts().plot(ax=ax, kind='bar')\n",
    "\n",
    "# Split training and testing data\n",
    "text_train, y_train = reviews_train.COMMENTS.tolist(), reviews_train.REQUESTTYPE.tolist()\n",
    "text_train_sub,text_val,y_train_sub,y_val = train_test_split(text_train,y_train,random_state=0)\n",
    "\n",
    "y_train_sub=np.asarray(y_train_sub)\n",
    "y_val=np.asarray(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2 - Model 1 [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a baseline multi-class classification model using a bag-of-word approach, report macro f1-score (should be above .5) and visualize the confusion matrix. Can you interpret the mistakes made by the model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use SGDClassifier as classfication method, and get score as 0.543\n",
    "# Confusion matrix is used to show the result\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "_ = text_clf.fit(text_train_sub, y_train_sub)\n",
    "predicted = text_clf.predict(text_val)\n",
    "\n",
    "print (np.mean(predicted == y_val)) \n",
    "print(metrics.classification_report(y_val, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3 - Model 2 [30 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the model using more complex text features, including n-grams, character n-grams and possibly domain-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters in CountVectorizer, TfidTransformer, and Classification method to improve the accuracy\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),('tfidf', TfidfTransformer(use_idf=True)),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "_ = text_clf.fit(text_train_sub, y_train_sub)\n",
    "predicted = text_clf.predict(text_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task4 - Visualize Results [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results of the tuned model (classification results, confusion matrix, important features, example mistakes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the classification result, confusion matrix and other information \n",
    "print (np.mean(predicted == y_val)) \n",
    "print(metrics.classification_report(y_val, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task5 - Clustering [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply LDA, NMF and K-Means to the whole dataset. Can you find clusters or topics that match well with some of the ground truth labels? Use ARI to compare the methods and visualize topics and clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use K-Means to do the clustering, and set the number of cluster as 5\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(y_train)\n",
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task6 - Model 3 [30 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the class definition for REQUESTTYPE by using the results of the clustering and results of the previous classification model. Re-assign labels using either the results of clustering or using keywords that you found during data exploration. The labels must be semantically meaningful.\n",
    "The data has a large “other” category. Apply the topic modeling and clustering techniques to this subset of the data to find possible splits of this class.\n",
    "Report accuracy using macro average f1 score (should be above .53) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the clustering result to label the data\n",
    "# The improved method could highly improve the accuracy to 0.6369\n",
    "\n",
    "def improvedModel():\n",
    "    y_train = model.labels_\n",
    "    text_train_sub,text_val,y_train_sub,y_val = train_test_split(text_train,y_train,random_state=0)\n",
    "\n",
    "    y_train_sub=np.asarray(y_train_sub)\n",
    "    y_val=np.asarray(y_val)\n",
    "\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),('tfidf', TfidfTransformer(use_idf=True)),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "    _ = text_clf.fit(text_train_sub, y_train_sub)\n",
    "    predicted = text_clf.predict(text_val)\n",
    "\n",
    "    print (np.mean(predicted == y_val)) \n",
    "    print(metrics.classification_report(y_val, predicted))\n",
    "    return np.mean(predicted == y_val)\n",
    "\n",
    "\n",
    "def test_accuracy():\n",
    "    print (improvedModel())\n",
    "    assert(improvedModel()>0.62)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit [Up to +20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a word embedding representation like word2vec for step 3 and or step 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add your code for extra credit here. You may use multiple cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
